{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and settings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time base and a straight line fit\n",
    "t = np.arange(0, 10, 0.01)\n",
    "def stline(x, m, c):\n",
    "    return m * x + c\n",
    "y = stline(t, 3, 1.2)\n",
    "# Add Gaussian noise\n",
    "n = 1 * np.random.randn(len(t))\n",
    "yn = y + n\n",
    "# plt.plot(t, y, t, yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get errorbars from noise \n",
    "plt.plot(t, y, t, yn)\n",
    "plt.errorbar(t[::5], yn[::5], np.std(n), fmt='ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares Curve Fitting\n",
    "\n",
    "Assume we know somei about the function that underlies the observed data (for example, that it is linear or a polynomial function).  However, we don't know the coefficients of the various terms.  For example, say our function takes two parameters $p_1$ and $p_2$, and is a linear function of the time variable $t$: $g(t, p_1, p_2) = p_1 t + p_2$.  \n",
    "\n",
    "We have a number of *observations* $g_1, g_2, \\ldots, g_n$ of this function at different time instants $t_1, t_2, \\ldots, t_n$.  These observations can then be written as:\n",
    "\n",
    "$$\n",
    "\\mathbf{g} \\equiv\n",
    "\\begin{pmatrix}\n",
    "g_1 \\\\\n",
    "g_2 \\\\\n",
    "\\vdots \\\\\n",
    "g_n\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "t_1 & 1 \\\\\n",
    "t_2 & 1 \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "t_n & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "p_1 \\\\\n",
    "p_2\n",
    "\\end{pmatrix}\n",
    "\\equiv\n",
    "\\mathbf{M}\\mathbf{p}\n",
    "$$\n",
    "\n",
    "## Mean Square Error\n",
    "We can therefore define an error $\\varepsilon = \\mathbf{Mp}-\\mathbf{g}$ (note that this is itself a vector of point-wise errors), and a *mean-square error* or MSE as:\n",
    "\n",
    "$$\n",
    "E = \\varepsilon^T \\varepsilon = \\sum_{1}^{N} \\varepsilon_i = \\sum_1^N ((p_1 t_i + p_2) - g_i)^2\n",
    "$$\n",
    "\n",
    "The goal of *least squares fitting* is to find the parameters $p_i$ such that this MSE $E$ is minimized.  More details of how this works can be seen at [LibreTexts](https://math.libretexts.org/Bookshelves/Linear_Algebra/Interactive_Linear_Algebra_(Margalit_and_Rabinoff)/06%3A_Orthogonality/6.5%3A_The_Method_of_Least_Squares).\n",
    "\n",
    "In our case, we can use the `lstsq` function from the `numpy.linalg` library.  For this, we have to construct the $\\mathbf{M}$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use column_stack to put the vectors side by side\n",
    "M = np.column_stack([t, np.ones(len(t))])\n",
    "# Use the lstsq function to solve for p_1 and p_2\n",
    "(p1, p2), _, _, _ = np.linalg.lstsq(M, yn, rcond=None)\n",
    "print(f\"The estimated equation is {p1} t + {p2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot against the original input and compare\n",
    "yest = stline(t, p1, p2)\n",
    "plt.plot(t, y, t, yn, t, yest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear curve fitting\n",
    "\n",
    "What if your equation was not a linear function of the parameters?  For example:\n",
    "$$g(t; p_1, p_2) = e^{-p_1 t} + p_2$$\n",
    "\n",
    "The problem here is that we cannot create the $M$ matrix as a linear combination of $p_1$ and $p_2$!  We still have a notion of MSE:\n",
    "\n",
    "$$E = \\sum_1^N (g(t; p_1, p_2) - z_t)^2$$\n",
    "where $z_t$ are the observed values.  However, the least squares minimization techniques discussed earlier do not work.  \n",
    "\n",
    "## `curve_fit`\n",
    "\n",
    "The `scipy.optimize` library contains the `curve_fit` function that can perform a non-linear curve fitting on observed data.  Unlike the least squares method, here we need to feed in a parametrized function that can be used to estimate the parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function with nonlinear dependence on parameters\n",
    "def nlfunc(t, p1, p2):\n",
    "    return np.exp(-p1 * t) + p2\n",
    "z = nlfunc(t, 0.5, 0.5)\n",
    "# Reuse the same noise - we are lazy\n",
    "zn = z + 0.2*n\n",
    "plt.plot(t, z, t, zn)\n",
    "plt.errorbar(t[::10], zn[::10], np.std(n), fmt='ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the non-linear curve fit\n",
    "(zp1, zp2), pcov = curve_fit(nlfunc, t, zn)\n",
    "print(f\"Estimated function: exp(-{zp1}t) + {zp2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zest = nlfunc(t, zp1, zp2)\n",
    "plt.plot(t, z, t, zest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-linear sinusoidal function\n",
    "def sinfunc(t, p1, p2):\n",
    "    return p1 * np.sin(2 * np.pi * p2 * t)\n",
    "s = sinfunc(t, 5, 0.5)\n",
    "sn = s + 0.2*n\n",
    "# Fit with only first K points\n",
    "K = 100\n",
    "(sp1, sp2), _ = curve_fit(sinfunc, t[:K], sn[:K])\n",
    "print(f\"Estimated: {sp1} * sin(2*pi*{sp2}*t)\")\n",
    "# Regenerate data\n",
    "sest = sinfunc(t, sp1, sp2)\n",
    "plt.plot(t, s, t, sest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "- You are given several data sets in text format.  For each of them:\n",
    "  - Plot the data along with errorbars - explain how you obtain the size of the errorbars.\n",
    "  - Propose a possible best curve fit for each of the data sets.  The exact nature of the function is not given, but some clues may be available.  \n",
    "  - Perform a curve fitting using appropriate techniques for each of the data.  You need to explain whether you are choosing to use a linear or nonlinear curve fit, and why it is the right approach.  Comment on the accuracy of your approach and whether it gives a good result, or somei better could have been done.\n",
    "- For the straight line fit from the example above, compare the time taken, and accuracy of the fit, for `lstsq` *vs* `curve_fit`.  Comment on your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Straight Line\n",
    "The dataset given clearly represents a Straight line. First we start by plotting the errorbar of the dta given taking the size of the errorbar as the standard deviation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset1 into a list using the loadtext function\n",
    "data = np.loadtxt(\"dataset1.txt\")\n",
    "# Splitting the array into two list of X and Y\n",
    "data_x = data[:,0]\n",
    "data_y = data[:,1]\n",
    "\n",
    "#Plot the data along with errorbars\n",
    "plt.errorbar(data_x[::10] , data_y[::10], yerr=np.std(data_y), fmt='ro')\n",
    "\n",
    "# Add labels and title to the plot\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Dataset1 with Errorbars\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the curve fit\n",
    "This is done by first defining the function that is expected to give the data points, which in this case is a straight line. Then this function along with the data points are fed into the `curve_fit` fucntion from the `scipy.optimize` library. This function returns the parameters of the equation of the plot that is to be made. These parameters are then used to plot the curve along with the dataset given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the equation of straight lines\n",
    "def str_line(x,c,m):\n",
    "    return x*m + c\n",
    "\n",
    "# Getting the parameters of the straight line from teh curve_fit fucntion\n",
    "(C,M),_ = curve_fit(str_line, data_x,data_y)\n",
    "\n",
    "# Plottong the data along with the approximated curve\n",
    "plt.plot(data_x,data_y , label = \"Data\")\n",
    "plt.plot(data_x, M*data_x + C , label = \"Curve fit\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Straight line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sum of sin waves \n",
    "When the plot of the dataset os made, it is clear that the data is of the sum of three sin waves.  \n",
    "The errorbar uses the same concept as before and has the size of the standard deviation of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset1 into a list using the loadtext function\n",
    "data = np.loadtxt(\"dataset2.txt\")\n",
    "# Splitting the array into two list of X and Y\n",
    "data_x = data[:,0]\n",
    "data_y = data[:,1]\n",
    "\n",
    "#Plot the data along with errorbars\n",
    "plt.errorbar(data_x[::10] , data_y[::10], yerr=np.std(data_y), fmt='ro')\n",
    "\n",
    "# Add labels and title to the plot\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Dataset2 with Errorbars\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Fourier Transform to find the frequency of the sin functions in the signal\n",
    "Now we approach this problem using the Fast Fourier Transfrom, which helos us isolate the distinct frequency sine waves in teh total wave that is being represented.  After the FFT the resulting data is plotted to get an idea about the Frequency domain representation of the wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the length of the data\n",
    "n = len(data_y)\n",
    "\n",
    "#Making the fft of the data\n",
    "yf = abs(np.fft.rfft(data_y))\n",
    "xf = np.fft.rfftfreq(n, 1/n)\n",
    "\n",
    "#PLotting this points to get an idea of the fourier transform\n",
    "plt.plot(xf,yf)\n",
    "plt.title(\"FFT of the sum of sines\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and finding the peaks from the Fourier data\n",
    "It can be noted that the most prominent frequencies are at the very beginning and that the rest are just result of noise. This arguement is further backed by the original dataset which gives the impression of the sum of **sine** waves. Now this noise is removed by filtering the signal with some amplitude, say 250. This will reduce all the signal points that lower than 250 to 0 for and hence give the appropriate number of peaks. These peaks are then used in the next cell to make the final plot using the `curve_fit()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the fft output to remove the random peaks that appear due to the noise\n",
    "for i in range(0,len(yf)):\n",
    "    if yf[i]<250:\n",
    "        yf[i] = 0\n",
    "\n",
    "#FInding the peaks of the fft to notice the frequency of the sin wave\n",
    "peaks = find_peaks(yf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the curve fit\n",
    "This is done by first defining the function that is expected to give the data points, which in this case is the sum of 3 sine waves. Then this function along with the data points are fed into the `curve_fit` fucntion from the `scipy.optimize` library. This function returns the parameters of the equation of the plot that is to be made. These parameters are then used to plot the curve along with the dataset given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function for the curve fit fucntion\n",
    "def sinefunc(x,a1,a2,a3,a4,a5,a6,the1,the2,the3):\n",
    "    return a1*np.sin(a2*x+the1)+a3*np.sin(a4*x+the2)+a5*np.sin(a6*x+the3)\n",
    "\n",
    "# Getting the parameters from the curve_fit fucntion to plot it\n",
    "(a1,a2,a3,a4,a5,a6,the1,the2,the3),_=curve_fit(sinefunc,data_x[:259],data_y[:259])\n",
    "\n",
    "# Plotting the data given\n",
    "plt.plot(data_x,data_y, label = \"Data\")\n",
    "\n",
    "#Plotting the Approximated fucntion using curve_fit function\n",
    "plt.plot(data_x,sinefunc(data_x,a1,a2,a3,a4,a5,a6,the1,the2,the3), label = \"Curve fit\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Sum of sine\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Blackbody radiation curve\n",
    "A hint is given for this data set , revealing that this is the curve of the blackbody radiation experiment used to find the value of Plank's constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset1 into a list using the loadtext function\n",
    "data = np.loadtxt(\"dataset3.txt\")\n",
    "# Splitting the array into two list of X and Y\n",
    "data_x = data[:,0]\n",
    "data_y = data[:,1]\n",
    "\n",
    "#Plot the data along with errorbars\n",
    "plt.errorbar(data_x[::50] , data_y[::50], yerr=np.std(data_y), fmt='ro')\n",
    "\n",
    "# Add labels and title to the plot\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Dataset3 with Errorbars\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the curve fit\n",
    "This is done by first defining the function that is expected to give the data points, which in this case is a straight line. Then this function along with the data points are fed into the `curve_fit` fucntion from the `scipy.optimize` library. This function returns the parameters of the equation of the plot that is to be made. These parameters are then used to plot the curve along with the dataset given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function for the curve fit fucntion\n",
    "def plank(mu,T,h):\n",
    "    k = 1.38e-23\n",
    "    c = 3.0e8\n",
    "    return 2*h*mu**3/c**2*(1/(np.exp(h*mu/(k*T))-1))\n",
    "\n",
    "# Getting the parameters from the curve_fit fucntion to plot it\n",
    "(T,h),_=curve_fit(plank,data_x,data_y,p0=[2000,6.63e-34])\n",
    "\n",
    "#Plotting all the stuff to get the result\n",
    "plt.plot(data_x,data_y ,  label =\"Data points\")\n",
    "plt.plot(data_x,plank(data_x,T,h) , label = \"Curve fit\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Black Body radiation curve\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Some Random plot\n",
    "So from the data , its not really clear what the mathematical function related to this is. So I am finding the mean of Y for each value of X and then plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset1 into a list using the loadtext function\n",
    "data = np.loadtxt(\"dataset4.txt\")\n",
    "# Splitting the array into two list of X and Y\n",
    "data_x = data[:,0]\n",
    "data_y = data[:,1]\n",
    "\n",
    "#Plot the data along with errorbars\n",
    "plt.errorbar(data_x[::10] , data_y[::10], yerr=np.std(data_y), fmt='ro')\n",
    "# Add labels and title to the plot\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Dataset4 with Errorbars\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the curve fit\n",
    "Not much can be infered from the above data, so I decided to make a reasonable plot by finding the mean of y for each value of x and then plotting it. This is being done in the following code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of items that are unique in data_x\n",
    "xr = list(set(data_x))\n",
    "\n",
    "# Initialising a zero array of length 11\n",
    "mean_y=[0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "# Finding the mean of y for each unique value of X\n",
    "for x in xr:\n",
    "    sum = 0\n",
    "    for i in range(0,1000):\n",
    "        if data[i][0] == x:\n",
    "            sum += 1\n",
    "    for i in range(0,1000):\n",
    "        if data[i][0] == x:\n",
    "            mean_y[int(x)] += data[i][1]/sum\n",
    "            \n",
    "#Plotting all the stuff to get proper graph        \n",
    "plt.scatter(data_x,data_y , label = \"Data points\")\n",
    "plt.plot(xr,mean_y , 'r' , label = \"Appromitaed Curve\" )\n",
    "plt.legend()\n",
    "plt.xlabel(\"Data Set\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Some Randon curve\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result obtained from this is a curve that looks fine but can't really reason out why it happens."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Sidharth S Kumar EE21B130"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b76e693b44b3581cdfe447d90b2f450bdb15f1cc32286f81ee9918acfd7cde71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
